# 基于星火大模型的群聊对话分角色要素提取挑战赛

本项目基于星火大模型，旨在对群聊对话进行角色要素的提取。通过提供训练数据和相应的代码，可以训练自己的模型进行推理并复现结果。

## 项目结构

```
role-element-extraction/
├── code/
│   ├── data_process/
│   │   ├── data_process.py
│   │   ├── data_process_single.ipynb
│   ├── generate_results/
│   │   ├── generate_results.py
│   │   ├── generate_results_all_list.py
│   │   ├── generate_results_few_shot.py
│   │   ├── generate_results_vote.py
│   │   ├── SparkApi.py
│   ├── test.sh
│   ├── train.sh
├── prediction_result/
│   ├── result.json
├── user_data/
│   ├── test_processed.json
│   ├── train_final.json
│   ├── train_processed.json
├── xfcdata/
│   ├── dataset/
│   │   ├── test_data.json
│   │   ├── train.json
├── requirements.txt
├── README.md
```

## 数据处理

### 生成训练数据

运行以下命令以生成训练数据，在[讯飞星火大模型训练平台](https://training.xfyun.cn/model)训练Spark Pro模型，数据集保存在user_data下：

```bash
cd code
sh train.sh
```

### 生成推理结果

运行以下命令以生成推理结果，运行结果保存在prediction_result下：

```bash
cd code
sh test.sh
```

## 模型训练

### 数据处理

1. **数据清洗**

   1.1 移除标记和链接
   - **方法**：使用正则表达式去除文本中的特殊标记（如 `[Token]`）和 URL 链接。

   1.2 合并连续聊天记录
   - **方法**：对于每个聊天记录，将相同人的连续发言合并为一条，便于后续处理。

2. **分割聊天记录并去重**
- 将聊天记录按行分割成列表，然后去除重复的聊天记录，以减少冗余信息。

3. **信息提取**
- 对于每条聊天记录，生成一个包含以下信息的提取任务说明：
  - 从聊天记录中提取客户的相关信息（如姓名、手机号码、邮箱等）。
  - 保持 JSON 格式不变，未提取到的信息项保留为空。
  - 识别多个客户的信息。

4. **数据集扩展**
- 为了扩展数据集，我们将处理后的训练集数据重复填充，生成最终的训练数据集文件 `train_final.jsonl`。

### 训练策略

训练阶段采用多阶段训练策略，以实现高效的模型训练。该策略分为三个阶段，每个阶段具有不同的目标和超参数设置。

1. **第一阶段**
   - 主要任务：学习识别客户的能力特征。
   - 目标：为后续的精细化训练奠定基础。
   - 要求：模型只需正确识别聊天记录中的客户。

2. **第二阶段**
   - 训练集：完整的训练集。
   - 目标：输出正确的全部客户信息。
   - 学习率：较大的学习率 (lr=0.00008)，训练3个Epoch。
   - 目的：迫使模型快速拟合训练集，生成符合模板的Json格式和信息。

3. **第三阶段**
   - 训练集：不变。
   - 学习率：为了避免过拟合，学习率被更改为0.00001，训练2个Epoch。

三个阶段结束，模型基本收敛，可以进行推理生成。

## 模型推理

### 推理流程

推理策略的实现首先包括设置相关的API配置。接着，定义了两个辅助函数：`getText`函数用于将用户或助手的对话内容添加到文本列表中，`getlength`函数用于计算文本列表中所有内容的总长度。为了确保文本列表中的内容长度不超过8000个字符，还定义了`checklen`函数，当内容长度超过限制时删除最早添加的内容。

在核心处理部分，定义了`core_run`函数，负责与`SparkApi`进行交互，清空文本列表，获取用户输入并将其添加到文本列表中，调用`SparkApi`的`main`方法传入必要的参数和问题列表，将`SparkApi`的回答添加到文本列表中并返回助手的回答内容。

数据校验部分，通过定义`ensure_required_keys`函数确保输出的JSON数据包含所有必需字段，如果某个字段缺失或类型不正确，则填充默认值。然后，从指定的JSONL文件中读取每一行数据，解析为JSON格式，提取用户输入，调用`core_run`函数获取模型的返回值，并尝试将模型的输出解析为JSON格式。如果解析失败，则重新生成输出并确保其格式正确。最后，将处理后的结果存储在列表中，并写入到指定的JSON文件中，打印结果文件的存储路径。

### 推理策略

1. **模板填充**
   - 确保输出的JSON数据包含所有必需字段，如果某个字段缺失或类型不正确，则填充默认值。

2. **投票策略**
   - 多个模型的输出进行投票，选择出现次数最多的结果作为最终结果。

3. **Few-shot策略**
   - 利用少量训练集中的示例引导模型生成更准确的输出。
> 由于模型输入长度限制，Few-Shot策略无法完整输入，模型无法处理过长的示例+问题，效果不佳

4. **CoT策略**
   - 使模型输出结果后再次输出判断的理由，利用链式推理策略，逐步推导最终答案，确保准确性。
> 由于训练集中并没有CoT提示，模型思考能力不足，并不能理解输出的字段含义，所以CoT策略并不能提高正确性。

# Attention
复现结果时，由于保证模型能最大程度上输出更多的内容，我们的温度被设置为0.1，这导致模型输出结果的不稳定性，复现结果时需要多次运行模型以获取最好效果。
## 许可

本项目遵循MIT许可协议。